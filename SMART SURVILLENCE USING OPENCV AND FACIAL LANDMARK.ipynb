{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition â€“ Unlock Your Computer With Your Face!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1 - Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = './faces/user/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "#cv2.face.createLBPHFaceRecognizer()\n",
    "#cv2.createLBPHFaceRecognizer()\n",
    "# cv2.face.LBPHFaceRecognizer_create()\n",
    "# Let's train our model \n",
    "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 1, Pixel Count: 307200\n",
      "Frame: 2, Pixel Count: 9588\n",
      "motion is deteced\n",
      "real\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "JAWLINE_POINTS = list(range(0, 17))\n",
    "RIGHT_EYEBROW_POINTS = list(range(17, 22))\n",
    "LEFT_EYEBROW_POINTS = list(range(22, 27))\n",
    "NOSE_POINTS = list(range(27, 36))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "MOUTH_OUTLINE_POINTS = list(range(48, 61))\n",
    "MOUTH_INNER_POINTS = list(range(61, 68))\n",
    "\n",
    "EYE_AR_THRESH = 0.22\n",
    "EYE_AR_CONSEC_FRAMES = 3\n",
    "EAR_AVG = 0\n",
    "\n",
    "COUNTER = 0\n",
    "TOTAL = 0\n",
    "counter=0\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "# fgbg = cv2.createBackgroundSubtractorMOG2(50, 200, True)\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(300, 400, True)\n",
    "\n",
    "# Keeps track of what frame we're on\n",
    "frameCount = 0\n",
    "\n",
    "while(1):\n",
    "\n",
    "\tret, frame = capture.read()\n",
    "\n",
    "\t#  Check if a current frame actually exist\n",
    "\tif not ret:\n",
    "\t\tbreak\n",
    "\n",
    "\tframeCount += 1\n",
    "\t# Resize the frame\n",
    "\t#resizedFrame = cv2.resize(frame, (0, 0), fx=0.50, fy=0.50)\n",
    "\n",
    "\t# Get the foreground mask\n",
    "\tfgmask = fgbg.apply(frame)\n",
    "\n",
    "\t# Count all the non zero pixels within the mask\n",
    "\tcount = np.count_nonzero(fgmask)\n",
    "\n",
    "\tprint('Frame: %d, Pixel Count: %d' % (frameCount, count))\n",
    "\n",
    "\t# Determine how many pixels do you want to detect to be considered \"movement\"\n",
    "\t# if (frameCount > 1 and cou`nt > 5000):\n",
    "\tif (frameCount > 1 and count > 5000):\n",
    "\t\tprint('motion is deteced')\n",
    "\t\tcv2.putText(frame, 'motion is deteced', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\t\tcounter=1\n",
    "\tcv2.imshow('Face Recognition', frame)\n",
    "\t#cv2.imshow('Mask', fgmask)\n",
    "\n",
    "\n",
    "\tk = cv2.waitKey(1) & 0xff\n",
    "\tif counter==1:\n",
    "\t\tbreak\n",
    "\n",
    "\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "\n",
    "\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "\n",
    "\n",
    "    ear = (A + B) / (2 * C)\n",
    "    return ear\n",
    "\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray, 0)\n",
    "        for rect in rects:\n",
    "            x = rect.left()\n",
    "            y = rect.top()\n",
    "            x1 = rect.right()\n",
    "            y1 = rect.bottom()\n",
    "\n",
    "            landmarks = np.matrix([[p.x, p.y] for p in predictor(frame, rect).parts()])\n",
    "\n",
    "            left_eye = landmarks[LEFT_EYE_POINTS]\n",
    "\n",
    "            right_eye = landmarks[RIGHT_EYE_POINTS]\n",
    "\n",
    "            left_eye_hull = cv2.convexHull(left_eye)\n",
    "            right_eye_hull = cv2.convexHull(right_eye)\n",
    "            cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1) # (image, [contour], all_contours, color, thickness)\n",
    "            cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)\n",
    "\n",
    "            ear_left = eye_aspect_ratio(left_eye)\n",
    "\n",
    "            ear_right = eye_aspect_ratio(right_eye)\n",
    "\n",
    "            ear_avg = (ear_left + ear_right) / 2.0\n",
    "\n",
    "            if ear_avg < EYE_AR_THRESH:\n",
    "                COUNTER += 1\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                    TOTAL += 1\n",
    "                    print(\"real\")\n",
    "                    cv2.putText(frame, \"Real\".format(ear_avg), (10, 60), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "                elif(TOTAL==0):\n",
    "                    cv2.putText(frame, \"Fake\".format(ear_avg), (10, 60), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 0, 255), 1)\n",
    "                COUNTER = 0\n",
    "              \n",
    "             \n",
    "            \n",
    "            cv2.putText(frame, \"Blinks{}\".format(TOTAL), (10, 30), cv2.FONT_HERSHEY_DUPLEX, 0.7, (0, 255, 255), 1)\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if TOTAL>0:\n",
    "            break\n",
    "\n",
    "print(TOTAL)\n",
    "\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        results = model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% LOOK HERE TO UNLOCK '\n",
    "            #cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,0), 2)\n",
    "        \n",
    "        if confidence > 89:\n",
    "            cv2.putText(image, \"Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "        else:\n",
    "            cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        #cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
